{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will take a data-driven approach to generating word lists for mental functions that are related to brain circuitry. The overall process is as follows:\n",
    "\n",
    "1. Cluster brain structures into circuits by PMI-weighted co-occurrences with mental function terms.\n",
    "2. Identify the mental function terms most highly associated to each circuit over a range of list lengths.\n",
    "3. Select the list length for each circuit that maximizes word-structure classification performance. \n",
    "4. Select the number of circuits that maximizes circuit-function classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utilities, ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_logreg\"\n",
    "cerebellum = \"seg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster range to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_counts = range(2, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain activation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Structure N=148\n"
     ]
    }
   ],
   "source": [
    "act_bin = utilities.load_coordinates(cerebellum=\"seg\")\n",
    "print(\"Document N={}, Structure N={}\".format(\n",
    "      act_bin.shape[0], act_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms for mental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 190325\n",
    "dtm_bin = utilities.load_doc_term_matrix(version=version, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = utilities.load_lexicon([\"cogneuro\"])\n",
    "lexicon = sorted(list(set(lexicon).intersection(dtm_bin.columns)))\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Term N=1683\n"
     ]
    }
   ],
   "source": [
    "dtm_bin = dtm_bin[lexicon]\n",
    "print(\"Document N={}, Term N={}\".format(\n",
    "      dtm_bin.shape[0], dtm_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training N=12708, Validation N=3631\n"
     ]
    }
   ],
   "source": [
    "train, val = [[int(pmid.strip()) \n",
    "               for pmid in open(\"../data/splits/{}.txt\".format(split))] \n",
    "                    for split in [\"train\", \"validation\"]]\n",
    "print(\"Training N={}, Validation N={}\".format(len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=2\n",
      "Processing k=3\n",
      "Processing k=4\n",
      "Processing k=5\n",
      "Processing k=6\n",
      "Processing k=7\n",
      "Processing k=8\n",
      "Processing k=9\n",
      "Processing k=10\n",
      "Processing k=11\n",
      "Processing k=12\n",
      "Processing k=13\n",
      "Processing k=14\n",
      "Processing k=15\n",
      "Processing k=16\n",
      "Processing k=17\n",
      "Processing k=18\n",
      "Processing k=19\n",
      "Processing k=20\n",
      "Processing k=21\n",
      "Processing k=22\n",
      "Processing k=23\n",
      "Processing k=24\n",
      "Processing k=25\n"
     ]
    }
   ],
   "source": [
    "k2terms, k2name = {}, {}\n",
    "for k in circuit_counts:\n",
    "    print(\"Processing k={}\".format(k))\n",
    "    lists, circuits = ontology.load_ontology(k, suffix=suffix, cerebellum=cerebellum)\n",
    "    k2terms[k] = {i: list(set(lists.loc[lists[\"CLUSTER\"] == i+1, \"TOKEN\"])) for i in range(k)}\n",
    "    k2name[k] = {i+1: \"\" for i in range(k)}\n",
    "    names, degs = [\"\"]*k, [0]*k\n",
    "    while \"\" in names:\n",
    "        for i in range(k):\n",
    "            degrees = ontology.term_degree_centrality(i+1, lists, dtm_bin, dtm_bin.index)\n",
    "            degrees = degrees.loc[k2terms[k][i]].sort_values(ascending=False)\n",
    "            name = degrees.index[0].upper().replace(\"_\", \" \")\n",
    "            if name not in names:\n",
    "                names[i] = name\n",
    "                degs[i] = max(degrees)\n",
    "                k2name[k][i+1] = name\n",
    "            elif name in names:\n",
    "                name_idx = names.index(name)\n",
    "                if degs[name_idx] > degs[i]:\n",
    "                    k2terms[k][i] = [term for term in k2terms[k][i] if term != name.lower().replace(\" \", \"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for k in circuit_counts:\n",
    "    names += list(k2name[k].values())\n",
    "names = sorted(list(set(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_in_order = [\n",
    "    'MEMORY',\n",
    "    'EPISODIC MEMORY',\n",
    "    'RETRIEVAL',\n",
    "    'EMOTION',\n",
    "    'MOOD',\n",
    "    'REWARD',\n",
    "    'VALENCE',\n",
    "    'DECISION MAKING',\n",
    "    'AGENCY',\n",
    "    'JUDGING',\n",
    "    'AROUSAL',\n",
    "    'ANTICIPATION',\n",
    "    'REACTION TIME',\n",
    "    'COGNITION',\n",
    "    'COGNITIVE',\n",
    "    'COGNITIVE FUNCTION',\n",
    "    'COGNITIVE PROCESS',\n",
    "    'REPRESENTATION',\n",
    "    'MANIPULATION',\n",
    "    'PLANNING',\n",
    "    'PREPARATION',\n",
    "    'EXECUTION',\n",
    "    'MOVEMENT',\n",
    "    'MOTOR CONTROL',\n",
    "    'MOTOR LEARNING',\n",
    "    'COORDINATION',\n",
    "    'ARM',\n",
    "    'FOOT',\n",
    "    'HAND',\n",
    "    'REST',\n",
    "    'HUNGER',\n",
    "    'VESTIBULAR',\n",
    "    'COVERT',\n",
    "    'VISION',\n",
    "    'IMAGERY',\n",
    "    'HEARING',\n",
    "    'PERCEPTION',\n",
    "    'LANGUAGE',\n",
    "    'WORD',\n",
    "    'MEANING'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2order = {}\n",
    "for k in circuit_counts:\n",
    "    name2i = {name: i for i, name in k2name[k].items()}\n",
    "    order = []\n",
    "    for i, name in enumerate(names_in_order):\n",
    "        if name in name2i.keys():\n",
    "            order.append(name2i[name])\n",
    "    k2order[k] = order\n",
    "k2name_ordered = {k: [k2name[k][i] for i in k2order[k]] for k in circuit_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['Manipulation', 'Movement'],\n",
       " 3: ['Arousal', 'Manipulation', 'Execution'],\n",
       " 4: ['Arousal', 'Manipulation', 'Movement', 'Hearing'],\n",
       " 5: ['Arousal', 'Cognitive', 'Movement', 'Vision', 'Hearing'],\n",
       " 6: ['Memory', 'Reward', 'Cognitive', 'Movement', 'Vision', 'Hearing'],\n",
       " 7: ['Memory',\n",
       "  'Reward',\n",
       "  'Cognitive',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Vision',\n",
       "  'Hearing'],\n",
       " 8: ['Emotion',\n",
       "  'Reward',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Vision',\n",
       "  'Language'],\n",
       " 9: ['Memory',\n",
       "  'Reward',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Vestibular',\n",
       "  'Vision',\n",
       "  'Language'],\n",
       " 10: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Vision',\n",
       "  'Perception',\n",
       "  'Language'],\n",
       " 11: ['Memory',\n",
       "  'Emotion',\n",
       "  'Anticipation',\n",
       "  'Cognitive',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Rest',\n",
       "  'Vision',\n",
       "  'Hearing'],\n",
       " 12: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Rest',\n",
       "  'Vestibular',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 13: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Reward',\n",
       "  'Reaction Time',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Rest',\n",
       "  'Vestibular',\n",
       "  'Vision',\n",
       "  'Perception',\n",
       "  'Language'],\n",
       " 14: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Rest',\n",
       "  'Vestibular',\n",
       "  'Vision',\n",
       "  'Perception',\n",
       "  'Language'],\n",
       " 15: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Cognitive',\n",
       "  'Cognitive Function',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Rest',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Language'],\n",
       " 16: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Rest',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 17: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Arousal',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Rest',\n",
       "  'Hunger',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 18: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Rest',\n",
       "  'Vestibular',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Language'],\n",
       " 19: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Mood',\n",
       "  'Reward',\n",
       "  'Agency',\n",
       "  'Cognitive',\n",
       "  'Cognitive Process',\n",
       "  'Representation',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Rest',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Meaning'],\n",
       " 20: ['Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Arousal',\n",
       "  'Cognition',\n",
       "  'Cognitive',\n",
       "  'Planning',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Foot',\n",
       "  'Hand',\n",
       "  'Rest',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Perception',\n",
       "  'Language',\n",
       "  'Word'],\n",
       " 21: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Arousal',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Foot',\n",
       "  'Hand',\n",
       "  'Rest',\n",
       "  'Hunger',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 22: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Reaction Time',\n",
       "  'Cognitive',\n",
       "  'Cognitive Function',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Foot',\n",
       "  'Rest',\n",
       "  'Hunger',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Meaning'],\n",
       " 23: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Judging',\n",
       "  'Arousal',\n",
       "  'Anticipation',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Foot',\n",
       "  'Rest',\n",
       "  'Hunger',\n",
       "  'Vision',\n",
       "  'Imagery',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Meaning'],\n",
       " 24: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Valence',\n",
       "  'Judging',\n",
       "  'Arousal',\n",
       "  'Anticipation',\n",
       "  'Cognition',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Motor Learning',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Foot',\n",
       "  'Hunger',\n",
       "  'Vestibular',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Meaning'],\n",
       " 25: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Retrieval',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Valence',\n",
       "  'Arousal',\n",
       "  'Anticipation',\n",
       "  'Cognition',\n",
       "  'Manipulation',\n",
       "  'Preparation',\n",
       "  'Execution',\n",
       "  'Movement',\n",
       "  'Motor Control',\n",
       "  'Coordination',\n",
       "  'Arm',\n",
       "  'Foot',\n",
       "  'Hand',\n",
       "  'Rest',\n",
       "  'Hunger',\n",
       "  'Covert',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Meaning']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2name_titles = {}\n",
    "for k in circuit_counts:\n",
    "    k2name_titles[k] = [dom.replace(\"_\", \" \").title() for dom in k2name_ordered[k]]\n",
    "k2name_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the term lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {\"red\": \"#CE7D69\", \"orange\": \"#BA7E39\", \"yellow\": \"#CEBE6D\", \"chartreuse\": \"#AEC87C\", \"green\": \"#77B58A\", \n",
    "     \"blue\": \"#7597D0\", \"magenta\": \"#B07EB6\", \"purple\": \"#7D74A3\", \"brown\": \"#846B43\", \"pink\": \"#CF7593\",\n",
    "     \"slate\": \"#6F8099\", \"crimson\": \"#8C4058\", \"gold\": \"#D8AE54\", \"teal\": \"#5AA8A7\", \"indigo\": \"#3A3C7C\", \n",
    "     \"lobster\": \"#FF7B5B\", \"olive\": \"#72662A\", \"lime\": \"#91E580\", \"sky\": \"#BCD5FF\", \"fuschia\": \"#E291DD\",\n",
    "     \"violet\": \"#8B75EA\", \"tan\": \"#E0BD84\", \"berry\": \"#D64F7C\", \"mint\": \"#A4EACA\", \"sun\": \"#F4FF6B\"}\n",
    "\n",
    "palettes = {\"data-driven\": [c[\"blue\"], c[\"magenta\"], c[\"yellow\"], c[\"green\"], c[\"red\"], \n",
    "                            c[\"purple\"], c[\"chartreuse\"], c[\"orange\"], c[\"pink\"], c[\"brown\"], \n",
    "                            c[\"slate\"], c[\"crimson\"], c[\"gold\"], c[\"teal\"], c[\"indigo\"],\n",
    "                            c[\"lobster\"], c[\"olive\"], c[\"lime\"], c[\"sky\"], c[\"fuschia\"],\n",
    "                            c[\"violet\"], c[\"tan\"], c[\"berry\"], c[\"mint\"], c[\"sun\"]],\n",
    "            \"rdoc\": [c[\"blue\"], c[\"red\"], c[\"green\"], c[\"purple\"], c[\"yellow\"], c[\"orange\"]],\n",
    "            \"dsm\": [c[\"purple\"], c[\"chartreuse\"], c[\"orange\"], c[\"blue\"], c[\"red\"], c[\"magenta\"], c[\"yellow\"], c[\"green\"], c[\"brown\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordclouds(k, domains, lists, dtm, framework=\"data-driven\", suffix=\"lr\", cerebellum=\"combo\"):\n",
    "\n",
    "    import os\n",
    "    from wordcloud import WordCloud\n",
    "    from style import style\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for i, dom in enumerate(domains):\n",
    "        \n",
    "        file_name = \"figures/lists/{}_{}_{}_kvals/k{:02d}_wordcloud_{}.png\".format(framework, suffix, cerebellum, k, dom)\n",
    "        if not os.path.exists(file_name):\n",
    "        \n",
    "            def color_func(word, font_size, position, orientation, \n",
    "                           random_state=None, idx=0, **kwargs):\n",
    "                return palettes[framework][i]\n",
    "\n",
    "            tkns = lists.loc[lists[\"DOMAIN\"] == dom, \"TOKEN\"]\n",
    "            freq = dtm[tkns].sum().values\n",
    "            tkns = [t.replace(\"_\", \" \") for t in tkns]\n",
    "            dic = {tkn: f for tkn, f in zip(tkns, freq)}\n",
    "\n",
    "            cloud = WordCloud(background_color=\"rgba(255, 255, 255, 0)\", mode=\"RGB\", \n",
    "                              max_font_size=100, prefer_horizontal=1, scale=20, margin=3,\n",
    "                              width=550, height=850, font_path=style.font, \n",
    "                              random_state=42).generate_from_frequencies(dic)\n",
    "\n",
    "            fig = plt.figure(1, figsize=(2,10))\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(cloud.recolor(color_func=color_func, random_state=42))\n",
    "            plt.savefig(file_name, \n",
    "                        dpi=800, bbox_inches=\"tight\")\n",
    "            utilities.transparent_background(file_name)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    lists, circuits = ontology.load_ontology(k, suffix=suffix, cerebellum=cerebellum)\n",
    "    lists[\"DOMAIN\"] = [k2name[k][i] for i in lists[\"CLUSTER\"]]\n",
    "    lists_ordered = pd.DataFrame()\n",
    "    for name in k2name_ordered[k]:\n",
    "        lists_ordered = lists_ordered.append(lists.loc[lists[\"DOMAIN\"] == name])\n",
    "    plot_wordclouds(k, k2name_ordered[k], lists_ordered, dtm_bin, cerebellum=cerebellum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from style import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ontol/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "atlas = utilities.load_atlas(cerebellum=cerebellum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "purples = style.make_cmap([(1,1,1), (0.365,0,0.878)])\n",
    "chartreuses = style.make_cmap([(1,1,1), (0.345,0.769,0)])\n",
    "magentas = style.make_cmap([(1,1,1), (0.620,0,0.686)])\n",
    "yellows = style.make_cmap([(1,1,1), (0.937,0.749,0)])\n",
    "browns = style.make_cmap([(1,1,1), (0.82,0.502,0)])\n",
    "pinks = style.make_cmap([(1,1,1), (0.788,0,0.604)])\n",
    "cmaps = [\"Blues\", magentas, yellows, \"Greens\", \"Reds\", \n",
    "         purples, chartreuses, \"Oranges\", pinks, browns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ontol/lib/python3.6/site-packages/nilearn/plotting/displays.py:767: UserWarning: empty mask\n",
      "  get_mask_bounds(new_img_like(img, not_mask, affine))\n"
     ]
    }
   ],
   "source": [
    "framework = \"data-driven\"\n",
    "for k in range(2, len(cmaps) + 1):\n",
    "    path = \"figures/circuits/{}_{}_{}_kvals/k{:02}\".format(framework, \"lr\", cerebellum, k)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    _, circuits = ontology.load_ontology(k, suffix=suffix)\n",
    "    circuits[\"DOMAIN\"] = [k2name[k][i] for i in circuits[\"CLUSTER\"]]\n",
    "    circuit_mat = pd.DataFrame(0.0, index=act_bin.columns, columns=k2name_ordered[k])\n",
    "    for name in k2name_ordered[k]:\n",
    "        structures = circuits.loc[circuits[\"DOMAIN\"] == name, \"STRUCTURE\"]\n",
    "        for structure in structures:\n",
    "            circuit_mat.loc[structure, name] = 1.0\n",
    "    utilities.map_plane(circuit_mat, atlas, path, \n",
    "                        suffix=\"_z\", cmaps=cmaps, plane=\"z\", cbar=False, vmin=0.0, vmax=2.0,\n",
    "                        verbose=False, print_fig=False, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the results\n",
    "\n",
    "## File structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    path = \"../../nke-cerebellum-viewer/data/k{:02d}\".format(k)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3d_object                 171.0\n",
       "abductive_reasoning         2.0\n",
       "abstract_analogy            3.0\n",
       "abstract_concrete_task      6.0\n",
       "abstract_knowledge         40.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = dtm_bin.sum(axis=0)\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    lists, _ = ontology.load_ontology(k, suffix=suffix, cerebellum=cerebellum)\n",
    "    lists[\"DOMAIN\"] = [k2name[k][i] for i in lists[\"CLUSTER\"]]\n",
    "    lists[\"CLUSTER\"] = [k2name_ordered[k].index(dom) + 1 for dom in lists[\"DOMAIN\"]]\n",
    "    lists[\"FREQUENCY\"] = [freq.loc[term] for term in lists[\"TOKEN\"]]\n",
    "    lists_ordered = pd.DataFrame()\n",
    "    for name in k2name_ordered[k]:\n",
    "        lists_ordered = lists_ordered.append(lists.loc[lists[\"DOMAIN\"] == name])\n",
    "    lists = lists.sort_values([\"CLUSTER\", \"R\"], ascending=[True, False])\n",
    "    file = \"../../nke-cerebellum-viewer/data/k{:02d}/words_k{:02d}.csv\".format(k, k)\n",
    "    lists.to_csv(file, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atlas_2mm(cerebellum=\"combo\"):\n",
    "\n",
    "    import numpy as np\n",
    "    from nilearn import image\n",
    "\n",
    "    cer = \"../data/brain/atlases/Cerebellum-MNIfnirt-maxprob-thr25-2mm.nii.gz\"\n",
    "    cor = \"../data/brain/atlases/HarvardOxford-cort-maxprob-thr25-2mm.nii.gz\"\n",
    "    sub = \"../data/brain/atlases/HarvardOxford-sub-maxprob-thr25-2mm.nii.gz\"\n",
    "\n",
    "    sub_del_dic = {1:0, 2:0, 3:0, 12:0, 13:0, 14:0}\n",
    "    sub_lab_dic_L = {4:1, 5:2, 6:3, 7:4, 9:5, 10:6, 11:7, 8:8}\n",
    "    sub_lab_dic_R = {15:1, 16:2, 17:3, 18:4, 19:5, 20:6, 21:7, 7:8}\n",
    "\n",
    "    sub_mat_L = image.load_img(sub).get_data()[46:,:,:]\n",
    "    sub_mat_R = image.load_img(sub).get_data()[:46,:,:]\n",
    "\n",
    "    for old, new in sub_del_dic.items():\n",
    "        sub_mat_L[sub_mat_L == old] = new\n",
    "    for old, new in sub_lab_dic_L.items():\n",
    "        sub_mat_L[sub_mat_L == old] = new\n",
    "    sub_mat_L = sub_mat_L + 48\n",
    "    sub_mat_L[sub_mat_L == 48] = 0\n",
    "\n",
    "    for old, new in sub_del_dic.items():\n",
    "        sub_mat_R[sub_mat_R == old] = new\n",
    "    for old, new in sub_lab_dic_R.items():\n",
    "        sub_mat_R[sub_mat_R == old] = new\n",
    "    sub_mat_R = sub_mat_R + 48\n",
    "    sub_mat_R[sub_mat_R == 48] = 0\n",
    "\n",
    "    cor_mat_L = image.load_img(cor).get_data()[46:,:,:]\n",
    "    cor_mat_R = image.load_img(cor).get_data()[:46,:,:]\n",
    "\n",
    "    mat_L = np.add(sub_mat_L, cor_mat_L)\n",
    "    mat_L[mat_L > 56] = 0\n",
    "    mat_R = np.add(sub_mat_R, cor_mat_R)\n",
    "    mat_R[mat_R > 56] = 0\n",
    "\n",
    "    if cerebellum == \"combo\":\n",
    "        mat_R = mat_R + 59\n",
    "        mat_R[mat_R > 118] = 0\n",
    "        mat_R[mat_R < 60] = 0\n",
    "\n",
    "    elif cerebellum == \"seg\":\n",
    "        mat_R = mat_R + 74\n",
    "        mat_R[mat_R > 148] = 0\n",
    "        mat_R[mat_R < 75] = 0\n",
    "\n",
    "    cer_mat_L = image.load_img(cer).get_data()[46:,:,:]\n",
    "    cer_mat_R = image.load_img(cer).get_data()[:46,:,:]\n",
    "\n",
    "    if cerebellum == \"combo\":\n",
    "        cer_mat_L[np.isin(cer_mat_L,[1,3,5,14,17,20,23,26])] = 57\n",
    "        cer_mat_L[np.isin(cer_mat_L,[8,11])] = 58\n",
    "        cer_mat_L[np.isin(cer_mat_L,[6,9,12,15,18,21,24,27])] = 59\n",
    "        cer_mat_R[np.isin(cer_mat_R,[2,4,7,16,19,22,25,28])] = 116\n",
    "        cer_mat_R[np.isin(cer_mat_R,[10,13])] = 117\n",
    "        cer_mat_R[np.isin(cer_mat_R,[6,9,12,15,18,21,24,27])] = 118\n",
    "\n",
    "        mat_L = np.add(mat_L, cer_mat_L)\n",
    "        mat_L[mat_L > 59] = 0\n",
    "        mat_R = np.add(mat_R, cer_mat_R)\n",
    "        mat_R[mat_R > 118] = 0\n",
    "\n",
    "    elif cerebellum == \"seg\":\n",
    "        cer_mat_L[cer_mat_L == 1] = 57\n",
    "        cer_mat_L[cer_mat_L == 3] = 58\n",
    "        cer_mat_L[cer_mat_L == 5] = 59\n",
    "        cer_mat_L[cer_mat_L == 6] = 69\n",
    "        cer_mat_L[cer_mat_L == 8] = 65\n",
    "        cer_mat_L[cer_mat_L == 9] = 67\n",
    "        cer_mat_L[cer_mat_L == 11] = 66\n",
    "        cer_mat_L[cer_mat_L == 12] = 68\n",
    "        cer_mat_L[cer_mat_L == 14] = 60\n",
    "        cer_mat_L[cer_mat_L == 15] = 70\n",
    "        cer_mat_L[cer_mat_L == 17] = 61\n",
    "        cer_mat_L[cer_mat_L == 18] = 71\n",
    "        cer_mat_L[cer_mat_L == 20] = 62\n",
    "        cer_mat_L[cer_mat_L == 21] = 72\n",
    "        cer_mat_L[cer_mat_L == 23] = 63\n",
    "        cer_mat_L[cer_mat_L == 24] = 73\n",
    "        cer_mat_L[cer_mat_L == 26] = 64\n",
    "        cer_mat_L[cer_mat_L == 27] = 74\n",
    "\n",
    "        cer_mat_R[cer_mat_R == 2] = 131\n",
    "        cer_mat_R[cer_mat_R == 4] = 132\n",
    "        cer_mat_R[cer_mat_R == 6] = 143\n",
    "        cer_mat_R[cer_mat_R == 7] = 133\n",
    "        cer_mat_R[cer_mat_R == 9] = 141\n",
    "        cer_mat_R[cer_mat_R == 10] = 139\n",
    "        cer_mat_R[cer_mat_R == 12] = 142\n",
    "        cer_mat_R[cer_mat_R == 13] = 140\n",
    "        cer_mat_R[cer_mat_R == 15] = 144\n",
    "        cer_mat_R[cer_mat_R == 16] = 134\n",
    "        cer_mat_R[cer_mat_R == 18] = 145\n",
    "        cer_mat_R[cer_mat_R == 19] = 135\n",
    "        cer_mat_R[cer_mat_R == 21] = 146\n",
    "        cer_mat_R[cer_mat_R == 22] = 136\n",
    "        cer_mat_R[cer_mat_R == 24] = 147\n",
    "        cer_mat_R[cer_mat_R == 25] = 137\n",
    "        cer_mat_R[cer_mat_R == 27] = 148\n",
    "        cer_mat_R[cer_mat_R == 28] = 138\n",
    "\n",
    "        mat_L = np.add(mat_L, cer_mat_L)\n",
    "        mat_L[mat_L > 75] = 0\n",
    "        mat_R = np.add(mat_R, cer_mat_R)\n",
    "        mat_R[mat_R > 148] = 0\n",
    "        \n",
    "    mat = np.concatenate((mat_R, mat_L), axis=0)\n",
    "    atlas_image = image.new_img_like(sub, mat)\n",
    "\n",
    "    return atlas_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_2mm = load_atlas_2mm(cerebellum=cerebellum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_pmi_by_fdr(pmi, act_bin, scores, n_iter=1000, verbose=False):\n",
    "    pmi_null = ontology.compute_cooccurrences_null(act_bin, scores, n_iter=n_iter, verbose=verbose)\n",
    "    p = pd.DataFrame(index=act_bin.columns, columns=scores.columns)\n",
    "    for i, struct in enumerate(act_bin.columns):\n",
    "        for j, dom in enumerate(scores.columns):\n",
    "            obs = pmi.values[i,j]\n",
    "            null = pmi_null[i,j,:]\n",
    "            p.loc[struct, dom] = np.sum(null > obs) / float(n_iter)\n",
    "    fdr = multipletests(p.values.ravel(), method=\"fdr_bh\")[1]\n",
    "    fdr = pd.DataFrame(fdr.reshape(p.shape), index=act_bin.columns, columns=scores.columns)\n",
    "    pmi_thres = pmi[fdr < 0.01]\n",
    "    pmi_thres = pmi_thres.fillna(0.0)\n",
    "    return pmi_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=02\n",
      "Processing k=03\n",
      "Processing k=04\n",
      "Processing k=05\n",
      "Processing k=06\n",
      "Processing k=07\n",
      "Processing k=08\n",
      "Processing k=09\n",
      "Processing k=10\n",
      "Processing k=11\n",
      "Processing k=12\n",
      "Processing k=13\n",
      "Processing k=14\n",
      "Processing k=15\n",
      "Processing k=16\n",
      "Processing k=17\n",
      "Processing k=18\n",
      "Processing k=19\n",
      "Processing k=20\n",
      "Processing k=21\n",
      "Processing k=22\n",
      "Processing k=23\n",
      "Processing k=24\n",
      "Processing k=25\n"
     ]
    }
   ],
   "source": [
    "for k in circuit_counts:\n",
    "    print(\"Processing k={:02d}\".format(k))\n",
    "    lists, circuits = ontology.load_ontology(k, suffix=suffix, cerebellum=cerebellum)\n",
    "    scores = utilities.score_lists(lists, dtm_bin, label_var=\"CLUSTER\").loc[act_bin.index]\n",
    "    pmi = ontology.compute_cooccurrences(act_bin, scores, positive=True)\n",
    "    pmi = threshold_pmi_by_fdr(pmi, act_bin, scores, n_iter=1000, verbose=False)\n",
    "    \n",
    "    for struct in pmi.index:\n",
    "        domain = circuits.loc[circuits[\"STRUCTURE\"] == struct, \"CLUSTER\"].values[0]\n",
    "        for k_i in range(1, k+1):\n",
    "            if k_i != domain:\n",
    "                pmi.loc[struct, k_i] = 0\n",
    "    \n",
    "    for f, feature in enumerate(k2order[k]):\n",
    "        stat_map = image.copy_img(atlas_2mm).get_data()\n",
    "        data = pmi[feature]\n",
    "        for i, value in enumerate(data):\n",
    "            stat_map[stat_map == i+1] = value\n",
    "        stat_img = image.new_img_like(atlas_2mm, stat_map)\n",
    "        \n",
    "        img_file = \"../../nke-cerebellum-viewer/data/k{:02d}/circuit_k{:02d}_dom{:02d}.nii.gz\".format(k, k, f+1)\n",
    "        stat_img.to_filename(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ontol] *",
   "language": "python",
   "name": "conda-env-ontol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
